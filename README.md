# E-commerce Data Scraper & Analytics Platform

A comprehensive Python-based e-commerce data scraping and analysis platform that extracts product information from online stores and provides detailed analytics, trend analysis, and automated reporting.

## Features

### Multi-Source Data Collection
- Scrapy Framework: Web scraping with zoommer.ge integration
- API Integration: Direct API access for efficient data collection
- Rate Limiting: Intelligent throttling and concurrent request management
- Error Handling: Robust retry logic and status code handling
- Multiple Categories: Phones, laptops, fridges, TVs support

### Data Processing & Validation
- Data Cleaning Pipeline: Automated validation and standardization
- Quality Scoring: 0-100 data quality assessment
- Multi-format Export: JSON, CSV, Excel output support
- Deduplication: Duplicate record removal
- Field Extraction: Automatic feature extraction (storage, RAM, etc.)

### Advanced Analytics
- Statistical Analysis: Descriptive statistics
- Trend Analysis: Time-based patterns and forecasting
- Price Analytics: Distribution analysis and market insights
- Brand Intelligence: Market share and positioning analysis
- Visualization: Automated chart generation (matplotlib/seaborn)

### Automated Reporting
- Executive Summaries: Key insights and recommendations
- Visual Reports: PNG charts and graphs
- Multiple Formats: JSON, HTML, and text reports
- Comparative Analysis: Cross-category and time-period comparisons

## Project Structure

```
ecommerce_scraper/
├── main.py                    # Main scraping and pipeline entry point
├── run_spider.py              # Simple spider runner
├── analyze_data.py            # Data analysis CLI
├── requirements.txt           # Python dependencies
├── config/                    # Configuration files
├── data_output/               # Output directory
│   ├── raw/                   # Raw scraped data
│   ├── processed/             # Cleaned and validated data
│   └── reports/               # Analysis reports and visualizations
├── src/
│   ├── analysis/              # Analytics modules
│   │   ├── statistics.py      # Statistical analysis
│   │   ├── trends.py          # Trend analysis
│   │   └── reports.py         # Report generation
│   ├── data/                  # Data processing
│   │   ├── processors.py      # Data cleaning and validation
│   │   ├── models.py          # Data models
│   │   └── database.py        # Database integration
│   ├── scrapers/              # Scraping modules
│   │   └── zoomer_scraper/    # Scrapy project for zoommer.ge
│   └── utils/                 # Utility functions
└── docs/                      # Documentation
```

## Installation

### Prerequisites
- Python 3.8+
- pip package manager

### Setup
```bash
# Clone the repository
git clone <repository-url>
cd ecommerce_scraper

# Install dependencies
pip install -r requirements.txt

# Create output directories
mkdir -p data_output/{raw,processed,reports}
```

### Key Dependencies
- scrapy - Web scraping framework
- pandas - Data manipulation and analysis
- matplotlib - Data visualization
- seaborn - Statistical visualization
- numpy - Numerical computing
- scipy - Scientific computing

## Quick Start

### 1. Basic Data Scraping

Scrape 10 phone products:
```bash
python main.py --category phones --max_products 10
```

Scrape 50 laptops:
```bash
python main.py --category laptops --max_products 50
```

Available categories: phones, laptops, fridges, tvs

### 2. Data Analysis

Analyze scraped data:
```bash
python analyze_data.py analyze --input data_output/raw/zoomer_phones_10.json
```

Complete pipeline (scrape + process + analyze):
```bash
# Step 1: Scrape data
python main.py --category phones --max_products 100

# Step 2: Run complete analysis
python analyze_data.py pipeline --input data_output/raw/zoomer_phones_100.json --output data_output/phone_analysis
```

## Complete Workflow Example

Scenario: Analyze 100 Phone Products

```bash
# 1. Scrape 100 phone products from zoommer.ge
python main.py --category phones --max_products 100

# 2. Run complete analysis pipeline
python analyze_data.py pipeline --input data_output/raw/zoomer_phones_100.json --output data_output/phone_analysis_100

# 3. View results
ls data_output/phone_analysis_100/
# Output:
# - ecommerce_analysis_report_[timestamp].json  (Detailed JSON report)
# - ecommerce_analysis_report_[timestamp].html  (HTML dashboard)
# - price_distribution.png                      (Price analysis charts)
# - category_analysis.png                       (Category breakdown)
# - brand_analysis.png                          (Brand market share)
# - time_analysis.png                           (Time-based patterns)
# - report_summary_[timestamp].txt              (Executive summary)
# - zoomer_phones_100_processed_[timestamp].csv (Clean data export)
```

Expected Results:
- Data Quality: ~95-100% validation rate
- Processing Time: ~2-3 minutes for 100 products
- Insights Generated: 10-15 key business insights
- Visualizations: 4 professional charts
- Export Formats: JSON, CSV, HTML reports

## Advanced Usage

### Data Processing Only
```bash
# Clean and validate existing data
python analyze_data.py process --input data_output/raw/zoomer_phones_50.json --output data_output/processed
```

### Multiple File Analysis
```bash
# Analyze multiple datasets together
python analyze_data.py analyze --input data_output/raw/zoomer_phones_50.json data_output/raw/zoomer_laptops_30.json --output data_output/combined_analysis
```

### Custom Output Directory
```bash
# Specify custom output location
python analyze_data.py pipeline --input data_output/raw/zoomer_laptops_100.json --output /custom/path/laptop_reports
```

### Export Format Selection
```bash
# Choose specific export formats
python analyze_data.py process --input data.json --formats json csv excel
```

## Analysis Features

### Statistical Analysis
- Descriptive Statistics: Mean, median, standard deviation, quartiles
- Distribution Analysis: Skewness, kurtosis, normality tests
- Price Intelligence: Outlier detection, price segmentation
- Market Analysis: Brand share, category performance

### Trend Analysis
- Time Patterns: Daily, hourly, weekly trends
- Price Trends: Historical price movements
- Volume Analysis: Scraping volume patterns
- Seasonal Patterns: Monthly and seasonal trends

### Data Quality
- Validation Rules: Required fields, price ranges, categories
- Quality Scoring: 0-100 quality score per record
- Data Cleaning: Text normalization, date standardization
- Feature Extraction: Storage capacity, RAM, specifications

### Visualizations
- Price Distribution: Histograms and box plots
- Category Analysis: Bar charts and pie charts
- Brand Analysis: Market share and price positioning
- Time Series: Trend lines and pattern analysis

## Configuration

### Scraping Settings (src/scrapers/zoomer_scraper/zoomer_scraper/settings.py)
```python
# Performance settings
DOWNLOAD_DELAY = 1                    # Delay between requests
CONCURRENT_REQUESTS = 4               # Concurrent requests
CONCURRENT_REQUESTS_PER_DOMAIN = 3    # Per-domain concurrency

# AutoThrottle settings
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_TARGET_CONCURRENCY = 2.0
```

### Analysis Settings
- Price Range Validation: 0-50,000 GEL
- Required Fields: source, name, price, brand, category, createdat
- Quality Thresholds: Configurable scoring criteria
- Export Formats: JSON, CSV, Excel support

## Sample Output

Executive Summary Example:
```
E-COMMERCE DATA ANALYSIS REPORT SUMMARY
==================================================

Generated: 2025-06-28 21:10:47
Total Records: 100
Date Range: 2025-06-28 to 2025-06-28

KEY INSIGHTS:
1. Average product price is 3,299 GEL
2. Apple dominates with 65.0% market share
3. Price distribution is heavily skewed towards lower prices
4. Peak scraping activity at 14:00-16:00
5. 98% data quality score achieved

Files Generated:
- JSON Report: ecommerce_analysis_report_20250628_211047.json
- HTML Dashboard: ecommerce_analysis_report_20250628_211047.html
- Visualizations: 4 PNG charts generated
- Clean Data: CSV and JSON exports available
```

Generated Files:
- price_distribution.png: Price histograms and box plots
- category_analysis.png: Category breakdown charts
- brand_analysis.png: Brand market share analysis
- time_analysis.png: Time-based pattern analysis
- report.html: Interactive HTML dashboard
- processed_data.csv: Clean, validated dataset

## Use Cases

### Market Research
- Competitive Analysis: Compare prices across brands
- Market Trends: Track pricing and availability patterns
- Product Intelligence: Identify popular features and specifications

### Business Intelligence
- Pricing Strategy: Understand market positioning
- Inventory Planning: Analyze product category performance
- Market Share: Track brand dominance and trends

### Data Science
- Price Prediction: Historical trend analysis
- Anomaly Detection: Identify unusual pricing patterns
- Customer Insights: Understand product preferences

## Troubleshooting

### Common Issues

1. Import Errors:
```bash
# Ensure all dependencies are installed
pip install -r requirements.txt
```

2. Empty Results:
```bash
# Check if data file exists and is valid JSON
python -m json.tool data_output/raw/zoomer_phones_10.json
```

3. Permission Errors:
```bash
# Ensure output directories exist
mkdir -p data_output/{raw,processed,reports}
```

4. Rate Limiting:
- Scraper automatically handles rate limiting
- Adjust DOWNLOAD_DELAY in settings if needed

### Debug Mode
```bash
# Enable verbose logging
python analyze_data.py analyze --input data.json --verbose
```

## Data Schema

### Raw Data Format:
```json
{
  "source": "zoommer.ge",
  "name": "Apple iPhone 16 Pro Max 256GB",
  "price": 3299,
  "brand": "Apple",
  "category": "phones",
  "description": "Detailed product specifications...",
  "createdat": "2025-06-28T17:08:36.141170"
}
```

### Processed Data Features:
- Quality Score: Data quality assessment (0-100)
- Extracted Features: Storage capacity, RAM, processor info
- Standardized Fields: Cleaned text, normalized prices
- Time Features: Date, hour, weekday derived fields

## Contributing

1. Fork the repository
2. Create a feature branch (git checkout -b feature/new-feature)
3. Commit changes (git commit -am 'Add new feature')
4. Push to branch (git push origin feature/new-feature)
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Links

- Project Repository: [GitHub Link]
- Documentation: /docs directory
- Issue Tracker: [GitHub Issues]
- Wiki: [Project Wiki]

## Project Status

Version: 1.0.0
Status: Production Ready
Last Updated: June 2025
Maintainer: Development Team

### Compliance
- University Project Requirements Met
- Industry Best Practices Applied
- Production-Grade Architecture
- Comprehensive Documentation